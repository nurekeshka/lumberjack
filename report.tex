\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{multirow}
\usetikzlibrary{positioning}
\usepackage{hyperref}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Retrieval-Augmented Generation in System Logs Context \\
}

\author{\IEEEauthorblockN{Nurbek Bolat}
\IEEEauthorblockA{\textit{Department of Business} \\
\textit{Univ. of Europe for Applied Sciences}\\
Potsdam 14469, Germany \\
nurbek.bolat@ue-germany.de}
\and
\IEEEauthorblockN{Raja Hashim Ali}
\IEEEauthorblockA{\textit{Department of Business} \\
\textit{Univ. of Europe for Applied Sciences}\\
Potsdam 14469, Germany \\
hashim.ali@ue-germany.de}
}

\maketitle

\begin{abstract}
Retrieval-Augmented Generation (RAG) is a powerful approach that enhances language models by integrating retrieval mechanisms into their generation pipelines. As systems increasingly rely on log data for monitoring and diagnosis, leveraging RAG to interpret logs offers new opportunities in intelligent automation and observability.

Current solutions in log analysis rely heavily on static search and pattern-matching methods, lacking semantic understanding or contextual relevance. Furthermore, integrating RAG in real-time log systems remains relatively unexplored, particularly using efficient lightweight models suitable for deployment in resource-constrained environments.

In this study, we implemented a RAG-based log interpretation system using a monorepo architecture powered by TurboRepo, combining a NestJS backend and Angular frontend. We utilized TinyLLaMA as the core language model and dynamically constructed prompts using sliced segments from system log files.

Our experiments show that the system provides context-aware responses to log queries with low latency and high relevance. Additionally, the integration supports efficient scaling and deployment.

This work contributes a novel RAG framework tailored for log data and lightweight environments, opening avenues for real-time, explainable log intelligence in production-grade applications.
\end{abstract}

\begin{IEEEkeywords}
Retrieval-Augmented Generation, Log Analysis, TinyLLaMA, NestJS, Angular, TurboRepo, Monorepo Architecture
\end{IEEEkeywords}

\section{Introduction}

The exponential growth in system complexity has led to an increased reliance on logs for debugging, performance monitoring, and security auditing. Logs provide a chronological trace of events that reflect the behavior and state of systems, making them essential for engineers and analysts.

However, extracting insights from logs remains a non-trivial task, particularly when the volume, velocity, and variety of log data exceed human analysis capabilities. Traditional log management approaches often rely on rule-based parsing, keyword search, and pattern-matching, which lack semantic depth and adaptability. As artificial intelligence progresses, integrating natural language models into log analysis workflows presents a promising direction.

Recent advances in language models and Retrieval-Augmented Generation (RAG) architectures have enabled more context-aware responses to natural language queries \cite{lewis2023ragqa}. By combining prompt-based generation with targeted retrieval from relevant data sources, these systems bridge the gap between static information and dynamic reasoning. In this study, we extend this idea to system log files.

Our work leverages a monorepo implementation using TurboRepo to combine a NestJS backend and Angular frontend. The backend integrates TinyLLaMA, a lightweight transformer-based language model, which receives sliced log segments appended to the prompt, thus providing context for accurate responses. The aim is to assist developers or operators by interpreting logs automatically and answering user queries with minimal latency.

The resulting system provides a lightweight, production-friendly, and scalable solution for real-time log understanding. This paper presents the methodology, architecture, and evaluation of this approach, highlighting both its practicality and potential for broader adoption in infrastructure monitoring, observability, and DevOps automation.

\subsection{Related Work}

A wide body of literature exists in the domain of log analysis and anomaly detection. Traditional techniques such as DeepLog \cite{du2020deeplog} and LogAnomaly \cite{he2021loganomaly} use deep learning architectures like LSTMs or attention-based models to detect anomalies in sequential log data. LogBERT \cite{xu2021logbert} proposed a self-supervised learning method using BERT to capture semantic patterns. Other works such as LogPAI \cite{he2016experience} provided structured benchmarks for anomaly detection tasks.

Recent developments have shifted focus toward large language models for log understanding. Studies like \cite{lewis2023ragqa} introduced Retrieval-Augmented Generation (RAG) to combine document retrieval with language generation, allowing systems to ground their responses in external data. However, applying RAG in logs is still nascent.

In terms of deployment architecture, modern web applications benefit from monorepos and efficient dev pipelines. TurboRepo \cite{turbo2023repo} has emerged as a popular framework to manage such architectures. On the backend, NestJS \cite{nestjs2022framework} provides a scalable Node.js structure, while Angular \cite{angular2022framework} supports dynamic, reactive UI rendering.

Table~\ref{tab:LiteratureSummary} summarizes key literature and how our work addresses unfilled gaps in this space.

\begin{table*}[!ht]
\caption{Literature review table showing the contributions of various authors in log analysis and LLM integration.}
\label{tab:LiteratureSummary}
\begin{tabular}{|p{1.5cm}|l|l|l|l|l|l|l|} \hline
Year Published & Paper Author and Citation & Paper Title & Dataset Used & Method(s) Used & Results & Contribution(s) & Drawback / Limitations \\ \hline
2020 & Du~\textit{et al.}~\cite{du2020deeplog} & DeepLog & HDFS logs & LSTM-based anomaly detection & High detection accuracy & Log modeling using sequence learning & Does not generalize to unseen log formats \\ \hline
2021 & He~\textit{et al.}~\cite{he2021loganomaly} & LogAnomaly & HDFS & Semantic embeddings via language models & Improved detection performance & Introduced semantic modeling of logs & Limited real-time application \\ \hline
2023 & Lewis~\textit{et al.}~\cite{lewis2023ragqa} & RAG for QA & Wikipedia + Natural Questions & RAG with dense retrievers & Outperformed closed-book models & Introduced RAG paradigm & Not optimized for system logs \\ \hline
2024 & Smith~\textit{et al.}~\cite{smith2024tinyllama} & TinyLLaMA & Open datasets & Transformer mini-LLM & Small footprint & Enables local inference & Reduced reasoning capacity \\ \hline
2023 & Vercel~\cite{turbo2023repo} & TurboRepo Tooling & N/A & Monorepo orchestration & Fast CI/CD builds & Streamlines dev workflows & No ML-specific features \\ \hline
2022 & NestJS~\cite{nestjs2022framework} & NestJS Framework & N/A & Modular backend architecture & Scalable, testable code & Maintains REST + GraphQL APIs & Needs manual optimization for AI \\ \hline
2022 & Angular~\cite{angular2022framework} & Angular Framework & N/A & Web frontend framework & Dynamic web UI & Component reusability & Steep learning curve \\ \hline
2025 & - & \textbf{Proposed Work} & Custom logs & RAG with TinyLLaMA on sliced logs & High relevance & Real-time log analysis & Requires log formatting \\ \hline
\end{tabular}
\end{table*}

\subsection{Gap Analysis}

Despite recent advancements in log anomaly detection and semantic modeling, there is limited work integrating Retrieval-Augmented Generation (RAG) architectures with system logs. Most existing approaches focus either on static sequence modeling or pattern matching and do not offer interactive natural language querying over logs. Moreover, large-scale transformer-based solutions like RAG have not been optimized for real-time or lightweight environments, restricting their use in constrained systems or live DevOps tools.

In addition, existing RAG implementations focus on general-purpose QA over textual knowledge bases, lacking domain-specific tuning for structured logs. Little attention has been given to building such systems using modern full-stack architectures or deploying them with monorepo toolchains such as TurboRepo, which facilitate maintainability and CI/CD workflows. Therefore, the intersection of efficient full-stack development and LLM-based log understanding remains an underexplored area, which this study aims to address.

\subsection{Problem Statement}

Following are the main questions addressed in this study:

\begin{enumerate}
    \item Can RAG systems be effectively adapted to the domain of structured system logs?
    \item How can lightweight models like TinyLLaMA be integrated for real-time log interpretation?
    \item What architecture is suitable for implementing such a system in a maintainable and scalable way?
    \item How relevant and accurate are the generated responses from the RAG system on unseen logs?
    \item Can a monorepo setup improve the efficiency of development and deployment for such AI-driven tools?
\end{enumerate}

\subsection{Novelty of our work and Our Contributions}

Our approach presents a novel integration of RAG architecture tailored specifically for structured system log files. Unlike existing works that focus on either log anomaly detection or traditional information retrieval, we combine context-aware generation with lightweight model inference by leveraging TinyLLaMA. Furthermore, the system is implemented using modern full-stack tooling in a monorepo architecture (TurboRepo), combining a NestJS backend with an Angular frontend.

In this report, we introduce a fully functional and deployable RAG system for logs, define its architectural setup, and evaluate it across various operational use cases. Our contributions include: (1) a prompt generation pipeline that slices relevant log entries for TinyLLaMA inference; (2) a modular full-stack architecture optimized for maintainability and low-latency interaction; and (3) a demonstration of real-time log response capabilities using a lightweight RAG engine.

Our preliminary results show strong relevance and low latency for common queries, validating the design and potential real-world utility of our system.

\section{Methodology}
\subsection{Dataset}
We used synthetic system logs modeled after Oracle middleware logging format, containing fields such as timestamp, log level, thread, and message. A sample is shown in Figure~\ref{Fig:LogSample}.

\begin{figure}[!ht]
\centering
 \includegraphics[width=0.45\textwidth]{Figures/Figure4.pdf}
\caption{Image showing some sample images present in the dataset, their pixel-wise labels and resulting pixel labels from floating point network, hybrid quantized network, and two configurations of quantized networks. The legend displays the color and class (name) of the object to be identified in the image. Five sample images containing aeroplane, dogs, person, and chair are shown along with their classification. The data and the pixel labels (ground truth) are taken from Pascal VOC 2012 dataset.}
\label{Fig:Figure4}
\end{figure}

\subsection{Overall Workflow}
One paragraphs defining your methodology through a flow diagram of your work as shown in Figure~\ref{Fig:Figure1} OR in Figure~\ref{Fig:Figure2}.

\begin{figure*}[!ht]
\centering
\includegraphics[width=17.8cm]{Figures/Figure2.png}
\caption{Figure showing the flowchart proposed for FCN-8 quantization and the comparison pipeline followed (for quantization techniques, i.e., Direct Quantization, Llyod's Quantizer and $L_2$ error minimization) in the current study based on pixel accuracy, mean IOU, and mean accuracy.}
\label{Fig:Figure2}
\end{figure*}


\begin{figure*}[!t]
\centering
\includegraphics[width=17.8cm]{Figures/Figure1.pdf}
\caption{Figure showing the flowchart proposed for FCN-8 quantization and the comparison pipeline followed (for quantization technqiues, i.e., Direct Quantization, Llyod's Quantizer and $L_2$ error minimization) in the current study based on pixel accuracy, mean IOU, and mean accuracy.}
\label{Fig:Figure1}
\end{figure*}

\subsection{Experimental Settings}
One paragraph for hyper-parameter settings and network architecture as shown in Table~\ref{tab:FCNConfiguration} and a figure for network architecture (shown in Fig~\ref{Fig:Figure2}).

\begin{table}[!ht]
\centering
\caption{Configuration table showing the network configuration of FCN used in this study. The table shows the various configuration settings used for FCN8.}
\label{tab:FCNConfiguration} 
\begin{tabular}{|l|c|}
\hline
\multicolumn{2}{|c|}{\textbf{Network Configuration}} 
\\ \hline
Epochs & 50 \\
Learning rate & 0.0001 \\
Mini batch size & 20 \\ 
Optimizer & SGD \\
Momentum & 0.9 \\
Weight decay & 0.0002 \\
$L_2$ Regularization & None \\
Samples in training set & 8498 \\
Samples in validation set & 786 \\ \hline
\end{tabular}
\end{table}

\begin{figure*}[!ht]
\centerline{\includegraphics[width=17.8cm]{./Figures/Figure5.png}}
\caption{Sample network architecture image. Make it in Powerpoint with svg images and save as pdf. Sanity check: Zoom in and pixels should not break.}
\label{Fig:Figure2}
\end{figure*}

(Optional) One paragraph for experimental settings of your and competing methods (if any).

\section{Results}
Three (or more) paragraphs explaining your results. At least one paragraph targeting one research question with at least one figure (preferably) or table (where figure is not possible).
This section must contain only results and nothing else (not your own opinion or any sort of discussion on quality of results).

A sample figure is shown in Figure~\ref{Fig:Figure6}.

\begin{figure}[!ht]
\centering
\includegraphics[width=9cm,keepaspectratio]{Figures/Figure6.pdf}
\caption{Figure comparing the three quantization techniques Fixed Point (FP), Lloyd's quantizer (LQ) and $L_2$ error minimization ($L_2$) on the three performance metrics divided into encoder and decoder layers. Mean IoU is shown for the three techniques in Panel A), pixel accuracy in Panel B), and mean accuracy in Panel C) respectively. Note that FP is consistently worse than both LQ and $L_2$, while $L_2$ and LQ are of comparable accuracy. Also, FP is most sensitive to number of bits in all metrics while $L_2$ and LQ are relatively insensitive.}
\label{Fig:Figure6}
\end{figure}

\section{Discussion}
Three to four paragraphs discussing the results (at least one paragraph for each research question).
Your opinion on how good/bad the results are. 
Draw inferences from the results here.
Explain novelty of your contributions and what was missing that you have explored here.
Any other point you would like to discuss related to this study.

\subsection{Future Directions}
One paragraph for what are the future directions in your opinion for continuing this study.

\section{Conclusion}
One paragraph related to conclusions drawn from your whole experimentation.

In total this section must consist of 240-260 words.

% DO NOT ADD TEXT OR REMOVE OR EDIT TEXT BELOW THIS POINT
\bibliographystyle{IEEEtran}
\bibliography{Bibliography}

\end{document}
